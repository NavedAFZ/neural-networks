{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bianry_class_NN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP8oU1Z7Lac4dm2LsiOIjGu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NavedAFZ/neural-networks/blob/master/bianry_class_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dmo6GKRRXHJo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import vstack\n",
        "from pandas import read_csv\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torch import Tensor\n",
        "from torch.nn import Linear\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import Sigmoid\n",
        "from torch.nn import Module\n",
        "from torch.optim import SGD\n",
        "from torch.nn import BCELoss\n",
        "from torch.nn.init import kaiming_uniform_\n",
        "from torch.nn.init import xavier_uniform_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGkVB1ZhXXA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CSV_data(Dataset):\n",
        "    # load the dataset\n",
        "    def __init__(self, path):\n",
        "        # load the csv file as a dataframe\n",
        "        df = read_csv(path, header=None)\n",
        "        # store the inputs and outputs\n",
        "        self.X = df.values[:, :-1]\n",
        "        self.y = df.values[:, -1]\n",
        "        # ensure input data is floats\n",
        "        self.X = self.X.astype('float32')\n",
        "        # label encode target and ensure the values are floats\n",
        "        self.y = LabelEncoder().fit_transform(self.y)\n",
        "        self.y = self.y.astype('float32')\n",
        "        self.y = self.y.reshape((len(self.y), 1))\n",
        " \n",
        "    # number of rows in the dataset\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        " \n",
        "    # get a row at an index\n",
        "    def __getitem__(self, idx):\n",
        "        return [self.X[idx], self.y[idx]]\n",
        " \n",
        "    # get indexes for train and test rows\n",
        "    def __split__(self, n_test=0.33):\n",
        "        # determine sizes\n",
        "        test_size = round(n_test * len(self.X))\n",
        "        train_size = len(self.X) - test_size\n",
        "        # calculate the split\n",
        "        return random_split(self, [train_size, test_size])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmfsPKaGugxS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "d30709cf-63d0-4a4f-8318-c90b3b18e8ad"
      },
      "source": [
        "pip install notebook --upgrade"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting notebook\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/f1/0a67f09ef53a342403ffa66646ee39273e0ac79ffa5de5dbe2f3e28b5bdf/notebook-6.0.3-py3-none-any.whl (9.7MB)\n",
            "\u001b[K     |████████████████████████████████| 9.7MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook) (4.3.3)\n",
            "Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook) (5.0.6)\n",
            "Requirement already satisfied, skipping upgrade: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook) (5.6.1)\n",
            "Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook) (2.11.2)\n",
            "Requirement already satisfied, skipping upgrade: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook) (0.8.3)\n",
            "Requirement already satisfied, skipping upgrade: ipykernel in /usr/local/lib/python3.6/dist-packages (from notebook) (4.10.1)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-client>=5.3.4 in /usr/local/lib/python3.6/dist-packages (from notebook) (5.3.4)\n",
            "Requirement already satisfied, skipping upgrade: prometheus-client in /usr/local/lib/python3.6/dist-packages (from notebook) (0.7.1)\n",
            "Collecting tornado>=5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/84/119a46d494f008969bf0c775cb2c6b3579d3c4cc1bb1b41a022aa93ee242/tornado-6.0.4.tar.gz (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 46.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook) (1.5.0)\n",
            "Requirement already satisfied, skipping upgrade: pyzmq>=17 in /usr/local/lib/python3.6/dist-packages (from notebook) (19.0.1)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-core>=4.6.1 in /usr/local/lib/python3.6/dist-packages (from notebook) (4.6.3)\n",
            "Requirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook) (2.6.0)\n",
            "Requirement already satisfied, skipping upgrade: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook) (0.8.4)\n",
            "Requirement already satisfied, skipping upgrade: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook) (2.1.3)\n",
            "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook) (1.4.2)\n",
            "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook) (0.3)\n",
            "Requirement already satisfied, skipping upgrade: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook) (0.4.4)\n",
            "Requirement already satisfied, skipping upgrade: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook) (3.1.5)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->notebook) (5.5.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.3.4->notebook) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook) (20.3)\n",
            "Requirement already satisfied, skipping upgrade: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook) (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook) (0.7.5)\n",
            "Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook) (4.8.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook) (46.3.0)\n",
            "Requirement already satisfied, skipping upgrade: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook) (1.0.18)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert->notebook) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook) (0.1.9)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlrQf4p6dXN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class my_model(Module):\n",
        "  def __init__(self,n_inputs):\n",
        "    super(my_model,self).__init__()\n",
        "    self.hidden1=Linear(n_inputs,10)\n",
        "    kaiming_uniform_(self.hidden1.weight,nonlinearity='relu')\n",
        "    self.act1=ReLU()\n",
        "    self.hidden2=Linear(10,8)\n",
        "    kaiming_uniform_(self.hidden2.weight,nonlinearity='relu')\n",
        "    self.act2=ReLU()\n",
        "    self.hidden3=Linear(8,1)\n",
        "    xavier_uniform_(self.hidden3.weight)\n",
        "    self.act3=Sigmoid()\n",
        "  def forward(self,X):\n",
        "    X=self.hidden1(X)\n",
        "    X=self.act1(X)\n",
        "    X=self.hidden2(X)\n",
        "    X=self.act2(X)\n",
        "    X=self.hidden3(X)\n",
        "    X=self.act3(X)\n",
        "    return X\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDMfHDHsieg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"def prepare_data(path):\n",
        "  dataset=CSV_data(path)\n",
        "  train,test=dataset.__split__()\n",
        "  train_loader=DataLoader(train,batch_size=32,shuffle=True)\n",
        "  test_loader=DataLoader(test,batch_size=1024,shuffle=False)\n",
        "  return train_loader,test_loader\"\"\"\n",
        "def prepare_data(path):\n",
        "    # load the dataset\n",
        "    dataset = CSV_data(path)\n",
        "    # calculate split\n",
        "    train, test = dataset.__split__()\n",
        "    # prepare data loaders\n",
        "    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
        "    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n",
        "    return train_dl, test_dl  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiX0wjKajp63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"def train_model(train_l,model):\n",
        "  loss_fn=BCELoss()\n",
        "  opt=SGD(model.parameters(),lr=0.1,momentum=0.9)\n",
        "  for epoch in range(100):\n",
        "    for i, (train_d,targets) in enumerate(train_l):\n",
        "      opt.zero_grad()\n",
        "      out=model(train_d)\n",
        "      loss=loss_fn(out,target)\n",
        "      loss.backward()\n",
        "      opt.step()\"\"\"\n",
        "def train_model(train_dl, model):\n",
        "    # define the optimization\n",
        "    criterion = BCELoss()\n",
        "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    # enumerate epochs\n",
        "    for epoch in range(100):\n",
        "        # enumerate mini batches\n",
        "        for  data in train_dl:\n",
        "          inputs, targets=data          \n",
        "          # clear the gradients\n",
        "          optimizer.zero_grad()\n",
        "          # compute the model output\n",
        "          yhat = model(inputs)\n",
        "          # calculate loss\n",
        "          loss = criterion(yhat, targets)\n",
        "          # credit assignment\n",
        "          loss.backward()\n",
        "          # update model weights\n",
        "          optimizer.step()      \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZejxxi0lu9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_model(test_dl, model):\n",
        "    predictions, actuals = list(), list()\n",
        "    for i, (inputs, targets) in enumerate(test_dl):\n",
        "        # evaluate the model on the test set\n",
        "        yhat = model(inputs)\n",
        "        # retrieve numpy array\n",
        "        yhat = yhat.detach().numpy()\n",
        "        actual = targets.numpy()\n",
        "        actual = actual.reshape((len(actual), 1))\n",
        "        # round to class values\n",
        "        yhat = yhat.round()\n",
        "        # store\n",
        "        predictions.append(yhat)\n",
        "        actuals.append(actual)\n",
        "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
        "    # calculate accuracy\n",
        "    acc = accuracy_score(actuals, predictions)\n",
        "    return acc\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbqXBKDKomTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model,data):\n",
        "  data1=Tensor([data])\n",
        "  out=model(data1)\n",
        "  out=out.detach().numpy()\n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSS3kUPXpIF3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "99841479-7e5e-4b3e-ca3c-090aa08e1814"
      },
      "source": [
        "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n",
        "train11,test11=prepare_data(path)\n",
        "print(len(train11.dataset), len(test11.dataset))\n",
        "mod1=my_model(34)\n",
        "\n",
        "train_model(train11,mod1)\n",
        "acc=evaluate_model(test11,mod1)\n",
        "print(acc)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "235 116\n",
            "0.9224137931034483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-P5dYiPqnRv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "52afbe0e-e685-4a9a-cb2f-f3fae1bdd547"
      },
      "source": [
        "print(mod1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_model(\n",
            "  (hidden1): Linear(in_features=34, out_features=10, bias=True)\n",
            "  (act1): ReLU()\n",
            "  (hidden2): Linear(in_features=10, out_features=8, bias=True)\n",
            "  (act2): ReLU()\n",
            "  (hidden3): Linear(in_features=8, out_features=1, bias=True)\n",
            "  (act3): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gceJyXYRsWmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}